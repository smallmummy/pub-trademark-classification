{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r TOKENIZER_FILE\n",
    "import pickle\n",
    "with open(TOKENIZER_FILE, \"rb\") as fr:\n",
    "    tokenizer = pickle.load(fr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare two model's embedding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 11:23:57.598171: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-14 11:23:57.598859: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally there are 19549200 elements in the weight, the amount same elements are: 2019730\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "MODEL_FILE = os.path.join(SOURCE_DIR, MODEL_FN)\n",
    "MODEL_FILE_1 = os.path.join(SOURCE_DIR, MODEL_FN_1)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "model = tf.keras.models.load_model(MODEL_FILE)\n",
    "model_1 = tf.keras.models.load_model(MODEL_FILE_1)\n",
    "\n",
    "amount_same = np.sum(model.layers[1].weights[0] == model_1.layers[1].weights[0])\n",
    "amount_total = (lambda x: x[0]*x[1])(model_1.layers[1].weights[0].shape)\n",
    "print(\n",
    "    f\"totally there are {amount_total} elements in the weight, \"\n",
    "    f\"the amount same elements are: {amount_same}\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how many words are still with zero in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 65164 in the matrix, finally still are 4962 words with all zero wights\n"
     ]
    }
   ],
   "source": [
    "total_words = model.layers[1].weights[0].shape[0]\n",
    "dim = model.layers[1].weights[0].shape[1]\n",
    "not_trained_words = np.sum(np.sum(model.layers[1].weights[0]==0, axis=1)==dim)\n",
    "\n",
    "print(\n",
    "    f\"there are {total_words} in the matrix, \"\n",
    "    f\"finally still are {not_trained_words} words with all zero wights\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentcheng/miniforge3/envs/tm_nlp/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/_pydev_imports_tipper.py:205: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "/Users/vincentcheng/miniforge3/envs/tm_nlp/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/_pydev_imports_tipper.py:205: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "/Users/vincentcheng/miniforge3/envs/tm_nlp/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/_pydev_imports_tipper.py:205: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n"
     ]
    }
   ],
   "source": [
    "pass\n",
    "# np.argwhere((np.sum(model.layers[1].weights[0]==0, axis=1)==dim)==True)\n",
    "for idx in np.argwhere((np.sum(model.layers[1].weights[0]==0, axis=1)==dim)==True):\n",
    "    term = tokenizer.index_word[idx]\n",
    "    df_no_exist_word[df_no_exist_word.term==term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r NO_EXIST_WORDS_FILE\n",
    "import pandas as pd\n",
    "df_no_exist_word = pd.read_csv(NO_EXIST_WORDS_FILE)\n",
    "\n",
    "df_tokenizer_map = pd.DataFrame.from_dict(tokenizer.index_word, orient='index')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型相关的统计分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集和测试集的cls分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cls_stat(np_class):\n",
    "    np_class = np_class.argmax(axis=1)+1\n",
    "    np_class.sort()\n",
    "    unique_idx = np.split(np.unique(np_class, return_index=True)[1], 45)\n",
    "    unique_idx = [int(item) for item in unique_idx]\n",
    "    unique_idx.append(np_class.shape[0])\n",
    "    cls_stat = [unique_idx[i + 1] - unique_idx[i]  for i in range(45)]\n",
    "    return cls_stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_stat_train = do_cls_stat(np_class_train)\n",
    "if sum(cls_stat_train) != np_class_train.shape[0]:\n",
    "    raise ValueError(\"class stat error\")\n",
    "\n",
    "cls_stat_test = do_cls_stat(np_class_test)\n",
    "if sum(cls_stat_test) != np_class_test.shape[0]:\n",
    "    raise ValueError(\"class stat error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_stat_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集和测试集在准确率（based on cls）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/344 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 10:54:48.216684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 4s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       203\n",
      "           1       0.98      1.00      0.99        60\n",
      "           2       1.00      0.97      0.98       398\n",
      "           3       1.00      0.98      0.99        42\n",
      "           4       1.00      1.00      1.00       250\n",
      "           5       1.00      0.97      0.98       189\n",
      "           6       0.98      0.98      0.98       345\n",
      "           7       0.97      0.97      0.97        78\n",
      "           8       0.97      1.00      0.98      1404\n",
      "           9       0.99      0.99      0.99       201\n",
      "          10       0.99      0.96      0.98       336\n",
      "          11       0.99      0.99      0.99       222\n",
      "          12       0.85      0.96      0.90        24\n",
      "          13       0.97      0.97      0.97        96\n",
      "          14       0.88      1.00      0.94        22\n",
      "          15       0.98      0.99      0.98       583\n",
      "          16       0.99      0.97      0.98       101\n",
      "          17       0.94      0.98      0.96       153\n",
      "          18       0.98      0.98      0.98       133\n",
      "          19       0.99      0.97      0.98       160\n",
      "          20       0.94      0.99      0.96       273\n",
      "          21       0.44      0.82      0.57        17\n",
      "          22       0.00      0.00      0.00         4\n",
      "          23       0.98      0.97      0.98        63\n",
      "          24       0.99      1.00      0.99       713\n",
      "          25       1.00      0.97      0.98        31\n",
      "          26       1.00      0.65      0.79        17\n",
      "          27       1.00      0.98      0.99       487\n",
      "          28       0.99      0.99      0.99       203\n",
      "          29       0.98      0.98      0.98       257\n",
      "          30       0.96      1.00      0.98        67\n",
      "          31       0.99      0.96      0.97        77\n",
      "          32       0.92      1.00      0.96        35\n",
      "          33       0.97      0.97      0.97        30\n",
      "          34       0.94      0.96      0.95       908\n",
      "          35       1.00      0.98      0.99       484\n",
      "          36       1.00      1.00      1.00       211\n",
      "          37       0.86      1.00      0.93       113\n",
      "          38       1.00      0.98      0.99       182\n",
      "          39       0.93      0.97      0.95       103\n",
      "          40       0.99      0.98      0.98       741\n",
      "          41       0.99      0.90      0.94       712\n",
      "          42       0.89      0.93      0.91        86\n",
      "          43       0.91      1.00      0.96       107\n",
      "          44       0.94      0.75      0.83        79\n",
      "\n",
      "    accuracy                           0.97     11000\n",
      "   macro avg       0.93      0.94      0.93     11000\n",
      "weighted avg       0.98      0.97      0.97     11000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentcheng/miniforge3/envs/tm_nlp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vincentcheng/miniforge3/envs/tm_nlp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vincentcheng/miniforge3/envs/tm_nlp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(TOKENIZED_GS_PICKLE_FILE, \"rb\") as fr:\n",
    "    tokenized_gs = pickle.load(fr)\n",
    "\n",
    "with open(TOKENIZED_CLASS_PICKLE_FILE, \"rb\") as fr:\n",
    "    tokenized_class = pickle.load(fr)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "model = tf.keras.models.load_model(MODEL_FILE)\n",
    "\n",
    "predictions = model.predict(tokenized_gs)\n",
    "report = classification_report(\n",
    "    tokenized_class.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1)\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      3138\n",
      "           1       0.78      0.83      0.80       796\n",
      "           2       0.89      0.93      0.91      3807\n",
      "           3       0.86      0.74      0.80       489\n",
      "           4       0.89      0.88      0.88      3453\n",
      "           5       0.81      0.86      0.84      2382\n",
      "           6       0.80      0.82      0.81      4928\n",
      "           7       0.80      0.78      0.79      1190\n",
      "           8       0.87      0.92      0.89     17958\n",
      "           9       0.87      0.81      0.84      2929\n",
      "          10       0.82      0.76      0.79      2874\n",
      "          11       0.78      0.80      0.79      2310\n",
      "          12       0.84      0.82      0.83       271\n",
      "          13       0.77      0.91      0.83       987\n",
      "          14       0.84      0.84      0.84       289\n",
      "          15       0.92      0.91      0.91      7473\n",
      "          16       0.70      0.75      0.72      1412\n",
      "          17       0.87      0.87      0.87      1242\n",
      "          18       0.75      0.78      0.76      1441\n",
      "          19       0.75      0.70      0.72      1770\n",
      "          20       0.77      0.81      0.79      2602\n",
      "          21       0.84      0.47      0.60       363\n",
      "          22       0.74      0.98      0.84        63\n",
      "          23       0.86      0.82      0.84      1000\n",
      "          24       0.95      0.97      0.96      4620\n",
      "          25       0.83      0.67      0.74       303\n",
      "          26       0.83      0.72      0.77       201\n",
      "          27       0.88      0.89      0.89      3068\n",
      "          28       0.86      0.93      0.89      2185\n",
      "          29       0.93      0.89      0.91      2929\n",
      "          30       0.87      0.83      0.85       718\n",
      "          31       0.93      0.87      0.90       544\n",
      "          32       0.92      0.94      0.93       299\n",
      "          33       0.86      0.83      0.85       205\n",
      "          34       0.85      0.84      0.84     10749\n",
      "          35       0.89      0.95      0.92      5277\n",
      "          36       0.89      0.80      0.85      2557\n",
      "          37       0.91      0.85      0.88      1397\n",
      "          38       0.89      0.83      0.86      1609\n",
      "          39       0.76      0.76      0.76      1239\n",
      "          40       0.92      0.94      0.93      9754\n",
      "          41       0.71      0.69      0.70      8950\n",
      "          42       0.60      0.79      0.68       755\n",
      "          43       0.62      0.68      0.65      1314\n",
      "          44       0.92      0.15      0.25      1160\n",
      "\n",
      "    accuracy                           0.85    125000\n",
      "   macro avg       0.83      0.81      0.81    125000\n",
      "weighted avg       0.85      0.85      0.85    125000\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed6a63b888fcb7d5f9ca97fbfdb77660060e60ab923755bd2b1564545ea9c047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
