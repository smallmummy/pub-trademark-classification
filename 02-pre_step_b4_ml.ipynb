{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-steps before ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r DF_INPUT_FILE\n",
    "%store -r EMBEDDING_DIM\n",
    "%store -r OOV_TOKEN\n",
    "%store -r WORD2VEC_BIN_FILE\n",
    "%store -r TOKENIZER_FILE\n",
    "%store -r NO_EXIST_WORDS_FILE\n",
    "%store -r NO_EXIST_WORDS_COUNT_STAT_FILE\n",
    "%store -r WORD2VEC_MATRIX_FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(DF_INPUT_FILE, \"rb\") as fr:\n",
    "    df = pickle.load(fr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "all_sentence_gs = df['gs'].values\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, oov_token=OOV_TOKEN)\n",
    "\n",
    "old_word_index = deepcopy(tokenizer.word_index)\n",
    "\n",
    "tokenizer.fit_on_texts(all_sentence_gs)\n",
    "\n",
    "for item in tokenizer.word_index.keys():\n",
    "    if item not in old_word_index.keys():\n",
    "        old_word_index[item] = len(old_word_index)+1\n",
    "\n",
    "tokenizer.word_index = old_word_index\n",
    "word_index = old_word_index\n",
    "# fetch counts for all words except oov_token\n",
    "words_count = json.loads(tokenizer.get_config()['word_counts'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "word2vec_matrix = KeyedVectors.load_word2vec_format(\n",
    "    datapath(WORD2VEC_BIN_FILE), binary=True\n",
    ")\n",
    "\n",
    "no_exist_words = {}\n",
    "\n",
    "for word in word_index.keys():\n",
    "    idx = word_index[word]\n",
    "    try:\n",
    "        embedding_matrix[idx] = word2vec_matrix[word]\n",
    "    except KeyError:\n",
    "        if word == OOV_TOKEN:\n",
    "            continue\n",
    "        no_exist_words[word] = words_count[word]\n",
    "    except Exception as e:\n",
    "        print(f\"halt due to fatal error:{str(e)}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_no_exist_words.shape = (30968, 2)\n",
      "df_no_exist_words.describe:                   c\n",
      "count  30968.000000\n",
      "mean       6.371351\n",
      "std       47.744301\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        3.000000\n",
      "max     3568.000000\n",
      "95% quantile at df_no_exist_words: c    18.0\n",
      "Name: 0.95, dtype: float64\n",
      "5% of df_no_exist_words = 1548.4\n"
     ]
    }
   ],
   "source": [
    "# 一些简单的统计\n",
    "import pandas as pd\n",
    "df_no_exist_words = pd.DataFrame.from_records(\n",
    "    [(k, v) for k,v in no_exist_words.items()],\n",
    "    columns=['term', 'c']\n",
    ")\n",
    "\n",
    "print(f\"df_no_exist_words.shape = {df_no_exist_words.shape}\")\n",
    "print(f\"df_no_exist_words.describe: {df_no_exist_words.describe()}\")\n",
    "print(f\"95% quantile at df_no_exist_words: {df_no_exist_words.quantile(0.95)}\")\n",
    "print(f\"5% of df_no_exist_words = {df_no_exist_words.shape[0] * 0.05}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vincentcheng/vc_code/personal_code/jupyter/TM_NLP/02-pre_step_b4_ml.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentcheng/vc_code/personal_code/jupyter/TM_NLP/02-pre_step_b4_ml.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vincentcheng/vc_code/personal_code/jupyter/TM_NLP/02-pre_step_b4_ml.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_no_exist_words\u001b[39m.\u001b[39;49mc\u001b[39m.\u001b[39;49mto_frame[\u001b[39m\"\u001b[39;49m\u001b[39mcount\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mplot\u001b[39m.\u001b[39mbox()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_no_exist_words.c.to_frame(\"count\").plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# 输出不存在于字典中的词\n",
    "df_no_exist_words.to_csv(NO_EXIST_WORDS_FILE)\n",
    "df_no_exist_words.groupby(\"c\").count().to_csv(NO_EXIST_WORDS_COUNT_STAT_FILE)\n",
    "\n",
    "\n",
    "# dump the tokenizer\n",
    "pickle.dump(\n",
    "    tokenizer, open(TOKENIZER_FILE, \"wb\")\n",
    ")\n",
    "# dump the embedding matrix\n",
    "pickle.dump(\n",
    "    embedding_matrix, open(WORD2VEC_MATRIX_FILE, \"wb\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tm_nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed6a63b888fcb7d5f9ca97fbfdb77660060e60ab923755bd2b1564545ea9c047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
